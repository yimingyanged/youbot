===================
  Quick Start
===================

1) Install ImageMagick from http://www.imagemagick.org
 (On most Linux systems this should already be installed. You can check by typing convert in a terminal)


Now you can generate some loop closures on
the test dataset located in ../Resources/Sample_Data/Images

2)  Assuming that your compiled binaries are in the bin directory, open a terminal in ./bin and call
  
   a)  ./WordMaker WordMaker_BatchConfig.moos
 
	This converts images to bag-of-words format.
	If you look in ../Resources/Sample_Data you should now see three new items:

	Surf			        - A directory containing the Surf features for each image.
	Words_VocabName 	    - A directory containing the bag-of-words for each image (with respect to the named vocabulary)
	Scenes_VocabName.oxs	- An index file listing image names, and the corresponding bag-of-words.
				  This index file is the input to FabMap


  Now run

   b) ./FabMap FabMap_BatchConfig.moos
	
	This runs the FabMap algorithm.
	The input is .oxs index file generated by WordMaker. Have a look in the config file (FabMap_BatchConfig.moos).
	
	Images are processed in the order in which they appear in the index file (corresponding to alphabetic sort by filename).
	For each image, we calculate the probability that it came from the same place as each of the previous images.
	
	The output will appear in the Results directory.
	The output is a matrix, the n-th entry of which corresponds to the pdf over previously seen places due to the n-th image.
	The final entry in each pdf is special - it is the probability that the query image came from a NEW place, not seen before.

	The default output format is plain text (extension .tmd).
	There is also an option to output Matlab matrices. Have a look in the configuration file FabMap_BatchConfig.moos
	
	A nice way to visualize the pdf in Matlab is to call imagesc(psame).
	Entry (i,j) in the matrix is the probability that image i came from the same place as image j.
	Loop closures should be visible as bright off-diagonal lines.
	Note that the main diagonal is special. Entry (i,i) in the matrix is the probability that image i came from a NEW place, not seen before.
	Therefore, high probability entries on the main diagonal indicate the detection of new places.
 
	

3) To run on your own data

Have a look in the configuration files.

	WordMaker_BatchConfig.moos
	and 
	FabMap_BatchConfig.moos

To run on your own data, just change the paths to point to your images.

We're using ImageMagick for loading images, so input can be almost any format you want. 
However, we find that compressed formats like jpeg or png typically add 200ms overhead compared to simple formats like pgm.

===================
  SOME PITFALLS
===================
  
A) THE ORDER IN WHICH IMAGES ARE PROCESSED CORRESPONDS TO ALPHABETICAL SORT BY FILENAME.

   For processing sequences of images, make sure that this corresponds to the order in which they were collected.
   We suggest naming the images by timestamp or with sequential numbers as in Sample_Data/Images

   If you want to process the images in some other order, you'll need to change the code to suit your needs.


B) CONSECUTIVE FRAMES OF VIDEO ARE NOT SUITABLE INPUT FOR THE ALGORITHM.

   The method assumes that the places in the map are disjoint (that is, their views don't overlap). 
   Because the method only detects loop closure about 20-40% of the time, with video input many similar places 
   can accumulate in the map, which causes problems.

   For best results, video input should be filtered with some form of keyframe detection.
   Simply taking every 30th or 40th frame should be sufficient to get reasonable results.
   Several such keyframe detectors can be configured from the FabMap_BatchConfig.moos config file.
   For our experiments, we trigger image capture when the robot moves more than 1.5 meters or turns more than 60 degrees.
   The resulting data has some overlap in consecutive views, especially with a forward-looking camera, however a little overlap doesn't seem to cause problems.


===================
 References
===================

For a quick intro to the ideas behind the system, see:
http://www.robots.ox.ac.uk/~mjc/appearance_based_results.htm

For a detailed description of how it works, see:
"FAB-MAP: Probabilistic Localization and Mapping in the Space of Appearance", Mark Cummins and Paul Newman, International Journal or Robotics Research, June 2008
http://www.robots.ox.ac.uk/~mjc/Papers/IJRR_2007.pdf

and

"Appearance-only SLAM at large scale with FAB-MAP 2.0", Mark Cummins and Paul Newman, International Journal or Robotics Research, November 2010.
http://www.robots.ox.ac.uk/~mjc/Papers/cummins_newman_ijrr_fabmap2_2010_preprint.pdf

The code in this distribution implements the FAB-MAP 2.0 algorithm.


Sample results:
http://www.robots.ox.ac.uk/~mjc/Video/NewCollege.avi
http://www.robots.ox.ac.uk/~mjc/Video/ScienceArea.avi

======================================
Last updated by mjc on 2008/5/16 
